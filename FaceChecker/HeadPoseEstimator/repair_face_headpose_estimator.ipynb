{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"repair_face_headpose_estimator.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"-Qw0rPUXusqv","colab_type":"code","outputId":"b4f010ab-a360-47fc-da2b-73516babc51b","executionInfo":{"status":"ok","timestamp":1563868965762,"user_tz":-420,"elapsed":836,"user":{"displayName":"Nguyen Viet Hoang","photoUrl":"","userId":"07668124258168641920"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sKHkvBfTvDYj","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/module/HeadPoseEstimator')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DwlodpJmXH_","colab_type":"code","outputId":"1361e9ce-6650-4743-d7c0-ebf27af14275","executionInfo":{"status":"ok","timestamp":1563875953217,"user_tz":-420,"elapsed":803,"user":{"displayName":"Nguyen Viet Hoang","photoUrl":"","userId":"07668124258168641920"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile Headpose.py\n","\n","\n","import os\n","import cv2\n","import sys\n","import numpy as np\n","from math import cos, sin\n","from moviepy.editor import *\n","from moviepy.editor import *\n","from keras import backend as K\n","import argparse\n","import matplotlib.pyplot as plt\n","from HeadPoseEstimator.face_direction.FSANET_model import FSA_net_Capsule, FSA_net_Var_Capsule,FSA_net_noS_Capsule\n","from HeadPoseEstimator.face_direction.FSANET_face_direction import *\n","from mtcnn.mtcnn import MTCNN\n","from keras.layers import Input,Average\n","from keras.models import Model\n","import time\n","from config import *\n","\n","class HeadposeEstimation:\n","\n","  def __init__(self,fsanet_model_path,option=None):\n","\n","      if option is None:\n","\n","         self.option = {\n","              'image_size' : 64,\n","              'num_capsule' : 3,\n","              'dim_capsule' : 16,\n","              'routings' : 2,\n","              'stage_num' : [3,3,3],\n","              'lambda_d' : 1,\n","              'num_classes' : 3,\n","              'image_size' : 64,\n","              'num_primcaps' : 7*3,\n","              'm_dim' : 5,\n","              'ad' : 0.6\n","         }\n","      else:\n","          self.option = option\n","\n","      self.image_size = self.option['image_size']\n","      self.channels = 3\n","\n","      fsanet_model_path = fsanet_model_path\n","\n","      S_set = [self.option['num_capsule'], \n","                    self.option['dim_capsule'], \n","                    self.option['routings'], \n","                    self.option['num_primcaps'], \n","                    self.option['m_dim']\n","                   ]\n","\n","      model1 = FSA_net_Capsule(self.option['image_size'], self.option['num_classes'], self.option['stage_num'], self.option['lambda_d'], S_set)()\n","\n","      model2 = FSA_net_Var_Capsule(self.option['image_size'], self.option['num_classes'], self.option['stage_num'], self.option['lambda_d'], S_set)()\n","\n","      self.option['num_primcaps'] = 8*8*3\n","\n","      S_set = [self.option['num_capsule'], \n","                    self.option['dim_capsule'], \n","                    self.option['routings'], \n","                    self.option['num_primcaps'], \n","                    self.option['m_dim']\n","                   ]\n","\n","      model3 = FSA_net_noS_Capsule(self.image_size, self.option['num_classes'], self.option['stage_num'], self.option['lambda_d'], S_set)()\n","\n","      print('Loading models ...')\n","\n","      weight_file1 = fsanet_model_path[0]\n","      model1.load_weights(weight_file1)\n","      print('Finished loading model 1.')\n","\n","      weight_file2 = fsanet_model_path[1]\n","      model2.load_weights(weight_file2)\n","      print('Finished loading model 2.')\n","\n","      weight_file3 = fsanet_model_path[2]\n","      model3.load_weights(weight_file3)\n","      print('Finished loading model 3.')\n","\n","      inputs = Input(shape=(self.image_size,self.image_size,self.channels))\n","\n","      x1 = model1(inputs) #1x1\n","      x2 = model2(inputs) #var\n","      x3 = model3(inputs) #w/o\n","\n","      avg_model = Average()([x1,x2,x3])\n","\n","      self.model = Model(inputs=inputs, outputs=avg_model)\n","      \n","  def getDirectionFromFaces(self,list_faces):\n","\n","    t = time.time()\n","\n","    if(len(list_faces)>0):\n","\n","      results = []\n","\n","      for face in list_faces:\n","\n","        info = {}\n","\n","        face = cv2.resize(face, (64,64))\n","\n","        face = cv2.normalize(face, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n","\n","        face = np.expand_dims(face, axis=0)\n","\n","        p_result = self.model.predict(face)\n","\n","        #img = draw_axis(list_faces, p_result[0][0], p_result[0][1], p_result[0][2])\n","\n","        info['direction'] = p_result\n","        info['face'] = input_img\n","\n","        if checkHeadPose(info):\n","             results.append(info)\n","\n","        print('head pose estimation time:{0:.2f}'.format(time.time()-t))\n","\n","    return results\n","\"\"\"  \n","  def getDirectionFromFaces(self,faces_coordinate,input_img):\n","\n","      t = time.time()\n","\n","      results = []  \n","\n","      if len(faces_coordinate) > 0:\n","\n","          print(len(faces_coordinate))    \n","\n","          img_h,img_w,_ = input_img.shape\n","\n","          faces = np.empty((len(faces_coordinate),self.image_size,self.image_size,self.channels))\n","\n","          for i, d in enumerate(faces_coordinate):\n","              info = {}\n","              x1,y1,w,h = d[0:4]\n","              x2,y2 = x1+w,y1+h\n","              x = (x1+x2)//2\n","              y = (y1+y2)//2\n","              print(x,y,w,h)\n","              xw1 = max(int(x - self.option['ad'] * w), 0)\n","              yw1 = max(int(y - self.option['ad'] * h), 0)\n","              xw2 = min(int(x + self.option['ad'] * w), img_w - 1)\n","              yw2 = min(int(y + self.option['ad'] * h), img_h - 1)\n","              #print(str(xw1)+' '+str(yw1)+' '+str(xw2)+' '+str(yw2))\n","\n","              print(input_img[yw1:yw2+1, xw1:xw2+1, :].shape)\n","\n","              faces[i,:,:,:] = cv2.resize(input_img[yw1:yw2+1, xw1:xw2+1, :], (64, 64))\n","              faces[i,:,:,:] = cv2.normalize(faces[i,:,:,:], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)        \n","\n","              face = np.expand_dims(faces[i,:,:,:], axis=0)\n","              p_result = self.model.predict(face)\n","              \n","              img = draw_axis(input_img[yw1:yw2+1, xw1:xw2+1, :], p_result[0][0], p_result[0][1], p_result[0][2])\n","              \n","              #print(p_result.shape)\n","              input_img[yw1:yw2+1, xw1:xw2+1, :] = img\n","\n","              info['box'] = [x1,y1,w,h]\n","              info['direction'] = p_result\n","              info['image'] = input_img\n","              \n","              if checkHeadPose(info):\n","                   results.append(info)\n","                  \n","      print('head pose estimation time:{0:.2f}'.format(time.time()-t))\n","\n","      return results\n","\"\"\"\n","\n","  def checkHeadPose(self,info):\n","       \n","      if (info['direction'][0] >=-HEAD_POSE_THRESHOLD and info['direction'][0] <=HEAD_POSE_THRESHOLD) \n","          and (info['direction'][1] >=-HEAD_POSE_THRESHOLD and info['direction'][1] <=HEAD_POSE_THRESHOLD) \n","          and (info['direction'][2] >=-HEAD_POSE_THRESHOLD and info['direction'][2] <= HEAD_POSE_THRESHOLD):\n","          \n","          return True\n","      \n","      return False\n","      "],"execution_count":7,"outputs":[{"output_type":"stream","text":["Overwriting Headpose.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jiPji1Qsvi-F","colab_type":"code","outputId":"2638106e-001f-4da4-93e1-7ad3b3d535b9","executionInfo":{"status":"ok","timestamp":1563766562541,"user_tz":-420,"elapsed":761,"user":{"displayName":"Nguyen Viet Hoang","photoUrl":"","userId":"07668124258168641920"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile face_direction/FSANET_face_direction.py\n","\n","import os\n","import cv2\n","import sys\n","import numpy as np\n","from math import cos, sin\n","from moviepy.editor import *\n","def draw_axis(img, yaw, pitch, roll, tdx=None, tdy=None, size = 80):\n","\n","    pitch = pitch * np.pi / 180\n","    yaw = -(yaw * np.pi / 180)\n","    roll = roll * np.pi / 180\n","    Pit = \"pit: \"+str(round(pitch,6))\n","    Yaw = \"yaw: \"+str(round(yaw,6))\n","    Roll = \"roll: \"+str(round(roll,6))\n","    #cv2.putText(img, text=Pit, org=(0, 45), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n","    #                    fontScale=0.50, color=(0, 0, 255), thickness=1)\n","    #cv2.putText(img, text=Yaw, org=(0, 75), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n","    #                    fontScale=0.50, color=(0, 255, 0), thickness=1)\n","    #cv2.putText(img, text=Roll, org=(0, 105), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n","    #                    fontScale=0.50, color=(255, 0, 0), thickness=1)                                        \n","    if tdx != None and tdy != None:\n","        tdx = tdx\n","        tdy = tdy\n","    else:\n","        height, width = img.shape[:2]\n","        tdx = width / 2\n","        tdy = height / 2\n","\n","    # X-Axis pointing to right. drawn in red\n","    x1 = size * (cos(yaw) * cos(roll)) + tdx\n","    y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n","\n","    # Y-Axis | drawn in green\n","    #        v\n","    x2 = size * (-cos(yaw) * sin(roll)) + tdx\n","    y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n","\n","    # Z-Axis (out of the screen) drawn in blue\n","    x3 = size * (sin(yaw)) + tdx\n","    y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n","\n","    cv2.line(img, (int(tdx), int(tdy)), (int(x1),int(y1)),(0,0,255),2)\n","    cv2.line(img, (int(tdx), int(tdy)), (int(x2),int(y2)),(0,255,0),2)\n","    cv2.line(img, (int(tdx), int(tdy)), (int(x3),int(y3)),(255,0,0),2)\n","\n","    return img\n","    \n","def draw_direction_results(results,input_img,faces,ad,img_size,img_w,img_h,model):\n","    if len(results) > 0:\n","        for i, d in enumerate(results):\n","            y1,x1,y2,x2 = d[1:5]\n","            x = (x1+x2)*img_w//2\n","            y = (y1+y2)*img_h//2\n","            w = h = max((x2-x1)*img_w, (y2-y1)*img_h)\n","            xw1 = max(int(x - ad * w), 0)\n","            yw1 = max(int(y - ad * h), 0)\n","            xw2 = min(int(x + ad * w), img_w - 1)\n","            yw2 = min(int(y + ad * h), img_h - 1)\n","            #print(str(xw1)+' '+str(yw1)+' '+str(xw2)+' '+str(yw2))\n","            faces[i,:,:,:] = cv2.resize(input_img[yw1:yw2+1, xw1:xw2+1, :], (img_size, img_size))\n","            faces[i,:,:,:] = cv2.normalize(faces[i,:,:,:], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)        \n","            \n","            face = np.expand_dims(faces[i,:,:,:], axis=0)\n","            p_result = model.predict(face)\n","            \n","            face = face.squeeze()\n","            img = draw_axis(input_img[yw1:yw2+1, xw1:xw2+1, :], p_result[0][0], p_result[0][1], p_result[0][2])\n","            #print(p_result.shape)\n","            input_img[yw1:yw2+1, xw1:xw2+1, :] = img\n","\n","    return input_img "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Overwriting face_direction/FSANET_face_direction.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hbZjhZnzv5QJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}